---
title: "Pilot Analyses"
output: 
    html_document:
      code_download: TRUE
      toc: TRUE
      toc_float:
        collapsed: FALSE
      toc_depth: 1
      code_folding: hide
editor_options: 
  chunk_output_type: console
---

```{r data prep, echo = FALSE, warning = FALSE, message = FALSE, error = FALSE}
# Loading packages
library(psych)
# library(sjPlot)
library(effects)
library(magrittr)
library(parameters)
library(dplyr)
library(tidyr)
library(rio)
library(ggplot2)
library(corrplot)
library(factoextra)

# Function to clean document
source("functions/cleaning.R")
source("functions/demographics counts.R")

# Setting global chunk options
knitr::opts_chunk$set(echo = TRUE,
                      message = FALSE,
                      warning = FALSE)

options(scipen = 999)

# Importing data
wide_raw <- import("data/pilot_raw_removed4.csv") 

# Cleaning data using function
clean_data <- get_clean_data(wide_raw)
```

# Descriptives {.tabset .tabset-fade .tabset-pills}

## Overall

```{r}
descrip_overall <- psych::describe(clean_data)
descrip_overall
```

## Sample size

```{r}
clean_data %>% 
  select(subid) %>% 
  unique() %>% 
  nrow()
```

### Per condition

```{r}
clean_data %>% 
  select(subid, condition) %>% 
  unique() %>% 
  group_by(condition) %>% 
  count()
```

A lot were removed from the competitive target in comparison to the other conditions.

## Histograms

### Distance in coffee shop

```{r}
hist(clean_data$distance_coffee)
````

Seat E is option "5," or the farthest seat away. It is left/negative-skewed to this option.

#### Is the skew non-normal?

```{r}
se_skew <- sqrt((6*211*(211-1))/((211-2)*(211+1)*(211+3)))
z_coffee <- descrip_overall$skew[13]/se_skew
z_coffee
```

According to Kim (2013; https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3591587/), a sample of 50 < n < 300 with an absolute z-score of >3.29 is non-normal. This z-score of -2.42 is less than 3.29, making the skew normal. 

Formula used for se of skew:
se_skew = sqrt(6*N*(N-1) / ((N-2)*(N+1)*(N+3)))

https://www.ibm.com/support/pages/standard-errors-skewness-and-kurtosis-are-all-same-set-variables

### Distance in town

```{r}
hist(clean_data$distance_town)
````

Right skewed (not as far of a distance), kind of plateaus at option 5.

#### Is the skew normal?

```{r}
z_town <- descrip_overall$skew[14]/se_skew
z_town
```

Using the same criteria as above (under histogram for distance from town), this is still normal skew.

### Realistic threat

```{r}
hist(clean_data$realistic_q)
````

Left/negative-skewed, with 4 = "Extremely threatening." I don't think this is concerning because it shows people are experiencing more threat overall and we had more threatening conditions than not.

#### Is the skew normal?

```{r}
z_realistic <- descrip_overall$skew[15]/se_skew
z_realistic
```

Using the same criteria as above (under histogram for distance from town), this is still normal skew.

### Symbolic threat

```{r}
hist(clean_data$symbolic_q)
````

Left/negative-skewed, same as with realistic threat above.

#### Is the skew normal?

```{r}
z_symbolic <- descrip_overall$skew[16]/se_skew
z_symbolic
```

Using the same criteria as above (under histogram for distance from town), this is still normal skew.

### Explicit threat posed by target

```{r}
hist(clean_data$explicit_targ)
````

Looks evenly spread out.

### Explicit threat posed by political out-group 

```{r}
hist(clean_data$explicit_group)
````

Left/negative skew. Seems people are more willing to discuss explicit threat of the group than the individual.

#### Is the skew normal?

```{r}
z_group <- descrip_overall$skew[18]/se_skew
z_group
```

This skew IS non-normal. Seems to be only moderately skewed, so going to start with a log transformation.

#### Fixing skew

```{r}
clean_data <- clean_data %>% 
  mutate(explicit_group_log = log10(max(explicit_group + 1)- explicit_group))

skew(clean_data$explicit_group_log)/se_skew
```

Z score is now below cut-off for transformed variable.

### Political orientation

#### Overall

```{r}
hist(clean_data$pol_orient_1)
````

Right/positive-skewed, not surprising as filtered for liberals and 1 = "extremely liberal"

#### Is the skew normal?

```{r}
z_polorient1 <- descrip_overall$skew[19]/se_skew
z_polorient1
```

Skew is non-normal.

##### Fixing skew

```{r}
clean_data <- clean_data %>% 
  mutate(pol_orient_1_log = log10(pol_orient_1))

skew(clean_data$pol_orient_1_log)/se_skew
```

Now the skew is normal.

#### Social 

```{r}
hist(clean_data$pol_orient_2)
````

Right/positive-skewed, still not surprised for the same reasons.

#### Is the skew normal?

```{r}
z_polorient2 <- descrip_overall$skew[20]/se_skew
z_polorient2
```

Skew is non-normal.

#### Fixing skew

```{r}
clean_data <- clean_data %>% 
  mutate(pol_orient_2_log = log10(pol_orient_2))

z_polorient2_log <- skew(clean_data$pol_orient_2_log)/se_skew
z_polorient2_log

clean_data <- clean_data %>% 
  mutate(pol_orient_2_inv = 1/(pol_orient_2))

z_polorient2_inv <- skew(clean_data$pol_orient_2_inv)/se_skew
z_polorient2_inv
```

The z-score with the log is still non-normal. Used inverse for severe skew, which is now normal.

#### Economic

```{r}
hist(clean_data$pol_orient_3)
````

Right/positive-skewed

#### Is the skew normal?

```{r}
z_polorient3 <- descrip_overall$skew[21]/se_skew
z_polorient3
```

Skew is non-normal.

#### Fixing skew

```{r}
clean_data <- clean_data %>% 
  mutate(pol_orient_3_log = log10(pol_orient_3))

skew(clean_data$pol_orient_3_log)/se_skew
```

Skew is now normal.

# Demographics {.tabset .tabset-fade .tabset-pills}

## Age

```{r}
clean_data %>%
  select(subid, age) %>% 
  na.omit() %>% 
  summarize(mean = mean(age),
            sd = sd(age))
```

## Gender

```{r}
gender_counts <- clean_data %>% 
  select(subid, gender) %>%  
  na.omit() %>% 
  unique() %>% 
  group_by(gender) %>% 
  count()

dem_percent_table(gender_counts)
```

Everyone responded to this question (211 when you add it up)

## Race/Ethnicity

```{r}
ethnicity_counts <- clean_data %>% 
  select(subid, race) %>%  
  na.omit() %>% 
  unique() %>% 
  group_by(race) %>% 
  count()

dem_percent_table(ethnicity_counts)
```

Everyone also responded to this question

## Education - Participant

```{r}
edu_counts <- clean_data %>% 
  select(subid, education) %>%  
  na.omit() %>% 
  unique() %>% 
  group_by(education) %>% 
  count()

dem_percent_table(edu_counts)
```

## Education - Parents

```{r}
edu_parent_counts <- clean_data %>% 
  select(subid, education) %>%  
  na.omit() %>% 
  unique() %>% 
  group_by(education) %>% 
  count()

dem_percent_table(edu_parent_counts)
```

## Birth country

```{r}
birth_country_counts <- clean_data %>% 
  select(subid, country_birth) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(country_birth) %>% 
  count()

dem_percent_table(birth_country_counts)
```

## Country raised

```{r}
raised_country_counts <- clean_data %>% 
  select(subid, country_raised) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(country_raised) %>% 
  count()

dem_percent_table(raised_country_counts)
```

### Follow-up years in US

```{r}
clean_data %>% 
  filter(country_raised != "Raised in US") %>% 
  select(raised_follow)
```

Should we removed the 5 primarily raised in another country? They all are US citizens and have lived in the US for 12-35 years. Seems like they have a good handle on US politics.

## Native language

```{r}
lang_counts <- language_counts <- clean_data %>% 
  select(subid, native_language) %>% 
  na.omit() %>% 
  unique() %>% 
  group_by(native_language) %>% 
  count()

dem_percent_table(lang_counts)
```

### Native language follow-up

```{r}
clean_data %>% 
  filter(native_language == "Not English") %>% 
  select(native_lang_follow)
```

Everyone has spoken for almost 20 years or more, so doesn't seem like we need to filter anyone out.

# Scale validation {.tabset .tabset-fade .tabset-pills}

## Correlation matrix

```{r}
# Getting only the variables in order to do an EFA
efa_data <- clean_data %>% 
  select(distance_coffee, distance_town, realistic_q, symbolic_q)

cor_matrix <- cor(efa_data)
cor_matrix

corrplot(cor_matrix, method = "number")
```

## EFA

### Can an EFA be run? 

```{r EFA check}
# Check factor structure to see if there is enough correlation, etc. for factor analysis
check_factorstructure(efa_data)
```

### What number of factors are advisable?

```{r EFA n factor check}
# What is the most recommended number of EFA factors?
factors_exp <- n_factors(efa_data)
factors_exp

# How many factors are supported by what number of methods?
summary(factors_exp)
```

It appears that 1 factor - as we had planned - is most advisable!

### 1 Factor EFA

```{r EFA 1 fac}
efa_1fac <- psych::fa(efa_data, nfactors = 1) %>% 
  model_parameters(sort = TRUE, threshold = "max")
efa_1fac
```

With the correlations not being as high for the distance measures and their respective factor loadings also being low on the one factor EFA, I am going to do a PCA and Scree Plot to see if the best factor should be reduced.

## PCA & Scree Plot

## PCA results

```{r}
pca_results <- prcomp(efa_data, scale = TRUE)
pca_results

eig.val <- get_eigenvalue(pca_results)
eig.val # Only dimension one has an eigenvalue over 1, but Dim 2 rounds to 1. Together they explain 76 % of the variance
  
# Results for Variables
res.var <- get_pca_var(pca_results)
res.var$coord          # Coordinates
res.var$contrib        # Contributions to the PCs
res.var$cos2           # Quality of representation 
```

The scaling option uses the variable standard deviations. When eigenvalues are obtained, Dimension 1 has an Eigenvalue over 1 and Dimension 2 has an eigenvalue equal to 1 when rounded. When looking at the contributions, it appears that Dimension 1 is explained by symbolic threat, realistic trheat, and distance in the coffee shop. Dimension 2 is mostly explained by distance in town and a little by distance in the coffee shop.

## Scree plot

```{r}
fviz_eig(pca_results)
```

Using eigenvalues to show percentage of variances explained by each component. 50% is explained by component 1, with a sharp dropoff occurring after component 1.

## Graph of variable correlations

```{r}
fviz_pca_var(pca_results,
             col.var = "contrib", # Color by contributions to the PC
             gradient.cols = c("cornflowerblue", "darkolivegreen3", "blueviolet"),
             repel = TRUE     # Avoid text overlapping
             )
```

Positively correlated variables point to the same side, while negatively correlated point to the other side. It shows the two different component dimensions that explain the most of the variance. Based on previous correlations and this visualization, nothing is negatively correlated, but some have weak correlations.

## Cronbach's alpha

### Alpha with 4 variables

```{r}
psych::alpha(efa_data)
```

Not at an acceptable reliability level

### Alpha with 3 variables

```{r}
efa_3 <- efa_data %>% 
  select(-distance_town)

psych::alpha(efa_3)
```

At an acceptable reliability level

## Current Thoughts

I think we need to drop the distance in town question, as it isn't reliable. We can have a one factor measure of implicit threat using symbolic threat, realistic threat, and distance in coffee shop. 

# Relationship with explicit threat {.tabset .tabset-fade .tabset-pills}

```{r}
threat_all <- clean_data %>% 
  select(distance_coffee, distance_town, realistic_q, symbolic_q, explicit_targ,
         explicit_group, explicit_group_log)

cor_matrix_all <- cor(threat_all)
cor_matrix_all

corrplot(cor_matrix_all, method = "number")
```

Should all of the variables be transformed to the same scale for reliable comparison? With the high correlations of explicit threat, it seems like it could be interesting to explore a scale with those and symbolic and realistic threat. Either way, our measures of symbolic and realistic threat are validated, as with the distance coffee measure having minor a minor correlation.

# ANOVA: Conditions prediciting threat

## Implicit threat

Currently using a composite of the three measures supported by my EFA/PCA analyses above: realistic threat, symbolic threat, and distance in coffee shop. Distance in town is not used. Since they are on different scales, converting to z-scores for the composite measure.

### Coverting variables to z-scores and composite measure

```{r}
comp1 <- clean_data %>% 
  mutate(realistic_z = (realistic_q - mean(realistic_q))/sd(realistic_q),
         symbolic_z = (symbolic_q - mean(symbolic_q))/sd(symbolic_q),
         coffee_z = (distance_coffee - mean(distance_coffee))/sd(distance_coffee)) %>%  #or should I use scale and convert them to a 0 to 1 range? )
  mutate(implicit_threat = rowMeans(select(., c("realistic_z", "symbolic_z", "coffee_z"))))

head(comp1)
mean(comp1$implicit_threat)
sd(comp1$implicit_threat)
```

### ANOVA

#### Summary results

```{r}
contrasts(comp1$condition)
results <- aov(implicit_threat ~ condition, data = comp1)
summary(results)
```

#### Post-hoc test

```{r}
TukeyHSD(results)
```

Control differs from warm targ, covid targ, comp targ, and loss targ
Loss targ and warm targ also differ from one another

The warm targ and comp targ do not differ (somewhat applicable to Study 1, but not post-hoc or female vs male)